{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c184f9e-1f3d-46d9-93f7-2f2e5f9d18bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.174.129:4042\n",
       "SparkContext available as 'sc' (version = 3.1.3, master = local[*], app id = local-1652297635318)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@1231d1f2\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark // Spark Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "234a96ce-a403-468d-ba26-f6e0e015be13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Movie\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// case class\n",
    "case class Movie(movieId: Int, title: String, genres: String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29607d28-2ad2-41fe-9954-e74a182c58fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "moviesFileRdd: org.apache.spark.rdd.RDD[String] = hdfs://localhost:9000/ml-latest-small/movies.csv MapPartitionsRDD[9] at textFile at <console>:27\n",
       "header: String = movieId,title,genres\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val moviesFileRdd = sc.textFile(\"hdfs://localhost:9000/ml-latest-small/movies.csv\")\n",
    "val header = moviesFileRdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd58b156-c12b-4d4a-b84a-8588fb1c59ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.SparkDriverExecutionException",
     "evalue": " Execution error",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.SparkDriverExecutionException: Execution error",
      "  at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1696)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2487)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2432)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2421)",
      "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)",
      "  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)",
      "  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)",
      "  at org.apache.spark.rdd.RDD.$anonfun$take$1(RDD.scala:1449)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
      "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)",
      "  at org.apache.spark.rdd.RDD.take(RDD.scala:1422)",
      "  at org.apache.spark.rdd.RDD.$anonfun$first$1(RDD.scala:1463)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)",
      "  at org.apache.spark.rdd.RDD.withScope(RDD.scala:414)",
      "  at org.apache.spark.rdd.RDD.first(RDD.scala:1463)",
      "  ... 36 elided",
      "Caused by: java.lang.ArrayStoreException: [LMovie;",
      "  at scala.runtime.ScalaRunTime$.array_update(ScalaRunTime.scala:75)",
      "  at org.apache.spark.SparkContext.$anonfun$runJob$4(SparkContext.scala:2217)",
      "  at org.apache.spark.SparkContext.$anonfun$runJob$4$adapted(SparkContext.scala:2217)",
      "  at org.apache.spark.scheduler.JobWaiter.taskSucceeded(JobWaiter.scala:59)",
      "  at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1692)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2487)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2432)",
      "  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2421)",
      "  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)",
      ""
     ]
    }
   ],
   "source": [
    "val moviesRdd = (moviesFileRdd.filter(line => line != header) // remove first header\n",
    "                            .map(line => line.split(\",\"))\n",
    "                            .map(arr => Movie(arr(0).toInt, arr(1), arr(2))))\n",
    "moviesRdd.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5788908-d9ed-47b4-9795-faad4790f36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|[1, Toy Story (19...|\n",
      "|[2, Jumanji (1995...|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "movieDf: org.apache.spark.sql.DataFrame = [value: array<string>]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val movieDf = moviesRdd.toDF()\n",
    "movieDf.printSchema()\n",
    "movieDf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e35ef-3158-4e2c-9cd1-e999eaf5b91a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
